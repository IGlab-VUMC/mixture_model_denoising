{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for negative binomial mixture model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-02\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio.Seq import Seq\n",
    "import Levenshtein as Lev\n",
    "\n",
    "# Load in custom functions\n",
    "from MM_functions import model_fit_functions as ff\n",
    "\n",
    "import os\n",
    "path = 'C:/Users/perry/Desktop/Atlas_analysis/'\n",
    "os.chdir(path)\n",
    "\n",
    "from datetime import datetime\n",
    "date = datetime.today().strftime('%Y-%m-%d')\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/perry/github_repos/mixed_model_denoising/'\n",
    "os.chdir(path)\n",
    "\n",
    "raw_files = os.listdir('./data/raw')\n",
    "raw_file_dict = dict(zip(list(range(1,len(raw_files) + 1)), raw_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-do:\n",
    "- Make sure I actually need all functions in python file\n",
    "- Modify them to make more unique\n",
    "- Make summary figs here (VRC01, and other visualizations that may be helpful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in raw files into dictionary\n",
    "raw_dfs = {}\n",
    "for donor in raw_file_dict:\n",
    "    donor_file = raw_file_dict[donor]\n",
    "    raw_dfs[donor] = pd.read_csv('./data/raw/' + donor_file, sep = ',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting names of unique antigens for LSS and UMI columns\n",
    "lss_names = [col for col in raw_dfs[1].columns if '.LSS' in col]\n",
    "umi_names = [i.split('.')[0] for i in lss_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "* Separate out donor cells and VRC01 negative control cells\n",
    "* Remove N > 1 (more than one heavy chain annotation)\n",
    "* Remove outliers from UMI count distributions (> 99th percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating subdirectories to store processed data\n",
    "try:\n",
    "    os.mkdir('./data/processed/')\n",
    "    os.mkdir('./data/processed/VRC01_cells')\n",
    "    os.mkdir('./data/processed/donor_cells')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# UMI to run pipeline on\n",
    "umi = 'SARS-2'\n",
    "\n",
    "# Only keeping N (# heavy chains), CDRH3 sequence, and UMI/LSS columns\n",
    "columns_to_keep = np.concatenate([lss_names, umi_names, ['N', 'CDR3_IMGT.H']])\n",
    "for donor in raw_dfs:\n",
    "    donor_df = raw_dfs[donor]\n",
    "    donor_df = donor_df[columns_to_keep]\n",
    "    # Separating out VRC01 cells\n",
    "    lseq_non_vrc01, vrc01_df = ff.separate_vrc01(donor_df)\n",
    "\n",
    "    # Removing N>1 cells Aand outliers in UMI counts\n",
    "    lseq_non_vrc01 = lseq_non_vrc01[lseq_non_vrc01['N'] == 1]\n",
    "    lseq_non_vrc01 = lseq_non_vrc01[lseq_non_vrc01[umi] < np.percentile(lseq_non_vrc01[umi], 99)]\n",
    "\n",
    "    if len (vrc01_df) >0:\n",
    "        vrc01_df = vrc01_df[vrc01_df['N'] == 1]\n",
    "        vrc01_df = vrc01_df[vrc01_df[umi] < np.percentile(vrc01_df[umi], 99)]\n",
    "\n",
    "    lseq_non_vrc01.to_csv('./data/processed/donor_cells/donor' + str(donor) + '_processed.csv')\n",
    "    vrc01_df.to_csv('./data/processed/VRC01_cells/donor' + str(donor) + '_vrc01_processed.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.10.4 ('scanpy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fbebedf494864f5a7bf1422628b41172b146a22fb331a68d487bf4abe44a60a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
